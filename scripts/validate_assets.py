#!/usr/bin/env python3
"""
Cinema Pro HDR èµ„äº§éªŒè¯è„šæœ¬
éªŒè¯ç”Ÿæˆçš„æµ‹è¯•èµ„äº§çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
import argparse
import sys

def validate_cliplist(cliplist_path: Path) -> bool:
    """éªŒè¯æ ·ç‰‡æ¸…å•"""
    print(f"ğŸ” éªŒè¯æ ·ç‰‡æ¸…å•: {cliplist_path}")
    
    try:
        with open(cliplist_path, 'r', encoding='utf-8') as f:
            cliplist = json.load(f)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ ·ç‰‡æ¸…å•: {e}")
        return False
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ['version', 'clips']
    for field in required_fields:
        if field not in cliplist:
            print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            return False
    
    clips = cliplist['clips']
    if len(clips) != 12:
        print(f"âŒ æ ·ç‰‡æ•°é‡é”™è¯¯: æœŸæœ›12ä¸ªï¼Œå®é™…{len(clips)}ä¸ª")
        return False
    
    # æ£€æŸ¥åœºæ™¯ç±»å‹åˆ†å¸ƒ
    scene_types = {}
    for clip in clips:
        scene_type = clip.get('type', 'unknown')
        scene_types[scene_type] = scene_types.get(scene_type, 0) + 1
    
    expected_types = {
        'night_scene': 2,
        'backlit_portrait': 2, 
        'neon': 2,
        'mist': 2,
        'highlight_peak': 2,
        'skin_tone': 2
    }
    
    for scene_type, expected_count in expected_types.items():
        actual_count = scene_types.get(scene_type, 0)
        if actual_count != expected_count:
            print(f"âŒ åœºæ™¯ç±»å‹ {scene_type} æ•°é‡é”™è¯¯: æœŸæœ›{expected_count}ä¸ªï¼Œå®é™…{actual_count}ä¸ª")
            return False
    
    # æ£€æŸ¥æ¯ä¸ªæ ·ç‰‡çš„å¿…éœ€å­—æ®µ
    required_clip_fields = ['id', 'name', 'type', 'duration_seconds', 'resolution', 'framerate']
    for i, clip in enumerate(clips):
        for field in required_clip_fields:
            if field not in clip:
                print(f"âŒ æ ·ç‰‡ {i+1} ç¼ºå°‘å­—æ®µ: {field}")
                return False
        
        # æ£€æŸ¥è§„æ ¼
        if clip['duration_seconds'] != 12:
            print(f"âŒ æ ·ç‰‡ {clip['id']} æ—¶é•¿é”™è¯¯: æœŸæœ›12ç§’ï¼Œå®é™…{clip['duration_seconds']}ç§’")
            return False
        
        if clip['resolution'] != '4096x2160':
            print(f"âŒ æ ·ç‰‡ {clip['id']} åˆ†è¾¨ç‡é”™è¯¯: æœŸæœ›4096x2160ï¼Œå®é™…{clip['resolution']}")
            return False
        
        if clip['framerate'] != 24:
            print(f"âŒ æ ·ç‰‡ {clip['id']} å¸§ç‡é”™è¯¯: æœŸæœ›24fpsï¼Œå®é™…{clip['framerate']}fps")
            return False
    
    print(f"âœ… æ ·ç‰‡æ¸…å•éªŒè¯é€šè¿‡: {len(clips)}ä¸ªæ ·ç‰‡ï¼Œ6ç§åœºæ™¯ç±»å‹")
    return True

def validate_curves(curves_path: Path) -> bool:
    """éªŒè¯RefMathæ›²çº¿æ•°æ®"""
    print(f"ğŸ” éªŒè¯RefMathæ›²çº¿: {curves_path}")
    
    try:
        curves_df = pd.read_csv(curves_path)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ›²çº¿æ•°æ®: {e}")
        return False
    
    # æ£€æŸ¥å¿…éœ€åˆ—
    required_columns = ['preset', 'curve_type', 'sample_index', 'x', 'y', 'monotonic', 'c1_continuous']
    for col in required_columns:
        if col not in curves_df.columns:
            print(f"âŒ ç¼ºå°‘å¿…éœ€åˆ—: {col}")
            return False
    
    # æ£€æŸ¥é¢„è®¾å’Œæ›²çº¿ç±»å‹
    expected_presets = {'cinema_flat', 'cinema_punch', 'cinema_highlight'}
    expected_curves = {'PPR', 'RLOG'}
    
    actual_presets = set(curves_df['preset'].unique())
    actual_curves = set(curves_df['curve_type'].unique())
    
    if actual_presets != expected_presets:
        print(f"âŒ é¢„è®¾ç±»å‹é”™è¯¯: æœŸæœ›{expected_presets}ï¼Œå®é™…{actual_presets}")
        return False
    
    if actual_curves != expected_curves:
        print(f"âŒ æ›²çº¿ç±»å‹é”™è¯¯: æœŸæœ›{expected_curves}ï¼Œå®é™…{actual_curves}")
        return False
    
    # æ£€æŸ¥æ¯ä¸ªé¢„è®¾-æ›²çº¿ç»„åˆçš„æ•°æ®å®Œæ•´æ€§
    total_combinations = len(expected_presets) * len(expected_curves)
    actual_combinations = len(curves_df.groupby(['preset', 'curve_type']))
    
    if actual_combinations != total_combinations:
        print(f"âŒ é¢„è®¾-æ›²çº¿ç»„åˆæ•°é‡é”™è¯¯: æœŸæœ›{total_combinations}ä¸ªï¼Œå®é™…{actual_combinations}ä¸ª")
        return False
    
    # æ£€æŸ¥é‡‡æ ·ç‚¹æ•°
    for (preset, curve_type), group in curves_df.groupby(['preset', 'curve_type']):
        sample_count = len(group)
        if sample_count != 16384:
            print(f"âŒ {preset}-{curve_type} é‡‡æ ·ç‚¹æ•°é”™è¯¯: æœŸæœ›16384ä¸ªï¼Œå®é™…{sample_count}ä¸ª")
            return False
        
        # æ£€æŸ¥xå€¼èŒƒå›´å’Œå•è°ƒæ€§
        x_values = group['x'].values
        if not (np.allclose(x_values[0], 0.0) and np.allclose(x_values[-1], 1.0)):
            print(f"âŒ {preset}-{curve_type} xå€¼èŒƒå›´é”™è¯¯: æœŸæœ›[0,1]ï¼Œå®é™…[{x_values[0]:.6f},{x_values[-1]:.6f}]")
            return False
        
        if not np.all(np.diff(x_values) > 0):
            print(f"âŒ {preset}-{curve_type} xå€¼ä¸æ˜¯ä¸¥æ ¼é€’å¢")
            return False
        
        # æ£€æŸ¥yå€¼èŒƒå›´
        y_values = group['y'].values
        if np.any(y_values < 0) or np.any(y_values > 1.1):  # å…è®¸è½»å¾®è¶…å‡º1.0
            print(f"âŒ {preset}-{curve_type} yå€¼è¶…å‡ºåˆç†èŒƒå›´: [{y_values.min():.6f},{y_values.max():.6f}]")
            return False
        
        # æ£€æŸ¥å•è°ƒæ€§æ ‡è®°
        monotonic_flag = group['monotonic'].iloc[0]
        actual_monotonic = np.all(np.diff(y_values) >= -1e-10)  # å…è®¸æ•°å€¼è¯¯å·®
        
        if monotonic_flag != actual_monotonic:
            print(f"âŒ {preset}-{curve_type} å•è°ƒæ€§æ ‡è®°é”™è¯¯: æ ‡è®°ä¸º{monotonic_flag}ï¼Œå®é™…ä¸º{actual_monotonic}")
            return False
    
    print(f"âœ… RefMathæ›²çº¿éªŒè¯é€šè¿‡: {len(curves_df)}æ¡è®°å½•ï¼Œ{total_combinations}ä¸ªé¢„è®¾-æ›²çº¿ç»„åˆ")
    return True

def validate_reference_data(reference_path: Path) -> bool:
    """éªŒè¯å‚è€ƒæ•°æ®JSON"""
    print(f"ğŸ” éªŒè¯å‚è€ƒæ•°æ®: {reference_path}")
    
    try:
        with open(reference_path, 'r', encoding='utf-8') as f:
            ref_data = json.load(f)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–å‚è€ƒæ•°æ®: {e}")
        return False
    
    # æ£€æŸ¥é¡¶å±‚å­—æ®µ
    required_fields = ['version', 'generator', 'precision', 'sample_count', 'presets', 'curves', 'validation']
    for field in required_fields:
        if field not in ref_data:
            print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            return False
    
    # æ£€æŸ¥ç²¾åº¦å’Œé‡‡æ ·æ•°
    if ref_data['precision'] != 'float64':
        print(f"âŒ ç²¾åº¦é”™è¯¯: æœŸæœ›float64ï¼Œå®é™…{ref_data['precision']}")
        return False
    
    if ref_data['sample_count'] != 16384:
        print(f"âŒ é‡‡æ ·æ•°é”™è¯¯: æœŸæœ›16384ï¼Œå®é™…{ref_data['sample_count']}")
        return False
    
    # æ£€æŸ¥é¢„è®¾æ•°é‡
    presets = ref_data['presets']
    if len(presets) != 3:
        print(f"âŒ é¢„è®¾æ•°é‡é”™è¯¯: æœŸæœ›3ä¸ªï¼Œå®é™…{len(presets)}ä¸ª")
        return False
    
    expected_preset_names = {'cinema_flat', 'cinema_punch', 'cinema_highlight'}
    actual_preset_names = set(presets.keys())
    
    if actual_preset_names != expected_preset_names:
        print(f"âŒ é¢„è®¾åç§°é”™è¯¯: æœŸæœ›{expected_preset_names}ï¼Œå®é™…{actual_preset_names}")
        return False
    
    # æ£€æŸ¥æ¯ä¸ªé¢„è®¾çš„å‚æ•°
    for preset_name, preset_data in presets.items():
        required_preset_fields = ['name', 'ppr', 'rlog', 'saturation']
        for field in required_preset_fields:
            if field not in preset_data:
                print(f"âŒ é¢„è®¾ {preset_name} ç¼ºå°‘å­—æ®µ: {field}")
                return False
        
        # æ£€æŸ¥PPRå‚æ•°
        ppr_params = preset_data['ppr']
        required_ppr_fields = ['pivot', 'gamma_s', 'gamma_h', 'shoulder']
        for field in required_ppr_fields:
            if field not in ppr_params:
                print(f"âŒ é¢„è®¾ {preset_name} PPRç¼ºå°‘å‚æ•°: {field}")
                return False
        
        # æ£€æŸ¥å‚æ•°èŒƒå›´
        if not (0.05 <= ppr_params['pivot'] <= 0.30):
            print(f"âŒ é¢„è®¾ {preset_name} pivotè¶…å‡ºèŒƒå›´: {ppr_params['pivot']}")
            return False
    
    # æ£€æŸ¥æ›²çº¿æ•°æ®
    curves = ref_data['curves']
    if len(curves) != 6:  # 3é¢„è®¾ Ã— 2æ›²çº¿
        print(f"âŒ æ›²çº¿æ•°æ®æ•°é‡é”™è¯¯: æœŸæœ›6ä¸ªï¼Œå®é™…{len(curves)}ä¸ª")
        return False
    
    # æ£€æŸ¥éªŒè¯ç»“æœ
    validation = ref_data['validation']
    if not validation.get('all_monotonic', False):
        print(f"âŒ å­˜åœ¨éå•è°ƒæ›²çº¿")
        return False
    
    if not validation.get('all_c1_continuous', False):
        print(f"âŒ å­˜åœ¨éCÂ¹è¿ç»­æ›²çº¿")
        return False
    
    print(f"âœ… å‚è€ƒæ•°æ®éªŒè¯é€šè¿‡: 3ä¸ªé¢„è®¾ï¼Œ6æ¡æ›²çº¿ï¼ŒéªŒè¯é€šè¿‡")
    return True

def validate_frames_metadata(frames_meta_path: Path) -> bool:
    """éªŒè¯å‚è€ƒå¸§å…ƒæ•°æ®"""
    print(f"ğŸ” éªŒè¯å‚è€ƒå¸§å…ƒæ•°æ®: {frames_meta_path}")
    
    try:
        with open(frames_meta_path, 'r', encoding='utf-8') as f:
            frames_meta = json.load(f)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–å‚è€ƒå¸§å…ƒæ•°æ®: {e}")
        return False
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ['version', 'description', 'frames']
    for field in required_fields:
        if field not in frames_meta:
            print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            return False
    
    frames = frames_meta['frames']
    expected_frame_count = 3 * 4  # 3é¢„è®¾ Ã— 4æ ·ç‰‡
    
    if len(frames) != expected_frame_count:
        print(f"âŒ å‚è€ƒå¸§æ•°é‡é”™è¯¯: æœŸæœ›{expected_frame_count}ä¸ªï¼Œå®é™…{len(frames)}ä¸ª")
        return False
    
    # æ£€æŸ¥æ¯ä¸ªå¸§çš„å¿…éœ€å­—æ®µ
    required_frame_fields = ['preset', 'clip_id', 'filename', 'description', 'expected_stats']
    for i, frame in enumerate(frames):
        for field in required_frame_fields:
            if field not in frame:
                print(f"âŒ å‚è€ƒå¸§ {i+1} ç¼ºå°‘å­—æ®µ: {field}")
                return False
    
    print(f"âœ… å‚è€ƒå¸§å…ƒæ•°æ®éªŒè¯é€šè¿‡: {len(frames)}ä¸ªå‚è€ƒå¸§")
    return True

def main():
    parser = argparse.ArgumentParser(description='éªŒè¯Cinema Pro HDRæµ‹è¯•èµ„äº§')
    parser.add_argument('--assets-dir', default='.', help='èµ„äº§æ ¹ç›®å½•')
    args = parser.parse_args()
    
    assets_dir = Path(args.assets_dir)
    
    print("ğŸš€ å¼€å§‹éªŒè¯Cinema Pro HDRæµ‹è¯•èµ„äº§...")
    print(f"ğŸ“ èµ„äº§ç›®å½•: {assets_dir.absolute()}")
    print()
    
    all_passed = True
    
    # éªŒè¯æ ·ç‰‡æ¸…å•
    cliplist_path = assets_dir / 'assets' / 'cliplist.json'
    if cliplist_path.exists():
        all_passed &= validate_cliplist(cliplist_path)
    else:
        print(f"âŒ æ ·ç‰‡æ¸…å•ä¸å­˜åœ¨: {cliplist_path}")
        all_passed = False
    
    print()
    
    # éªŒè¯RefMathæ›²çº¿
    curves_path = assets_dir / 'golden' / 'curves.csv'
    if curves_path.exists():
        all_passed &= validate_curves(curves_path)
    else:
        print(f"âŒ RefMathæ›²çº¿ä¸å­˜åœ¨: {curves_path}")
        all_passed = False
    
    print()
    
    # éªŒè¯å‚è€ƒæ•°æ®
    reference_path = assets_dir / 'golden' / 'reference_data.json'
    if reference_path.exists():
        all_passed &= validate_reference_data(reference_path)
    else:
        print(f"âŒ å‚è€ƒæ•°æ®ä¸å­˜åœ¨: {reference_path}")
        all_passed = False
    
    print()
    
    # éªŒè¯å‚è€ƒå¸§å…ƒæ•°æ®
    frames_meta_path = assets_dir / 'golden' / 'frames' / 'metadata.json'
    if frames_meta_path.exists():
        all_passed &= validate_frames_metadata(frames_meta_path)
    else:
        print(f"âŒ å‚è€ƒå¸§å…ƒæ•°æ®ä¸å­˜åœ¨: {frames_meta_path}")
        all_passed = False
    
    print()
    print("=" * 60)
    
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰èµ„äº§éªŒè¯é€šè¿‡ï¼")
        print("âœ… èµ„äº§å·²å‡†å¤‡å°±ç»ªï¼Œå¯ç”¨äºCIè§†è§‰å›å½’æµ‹è¯•")
        sys.exit(0)
    else:
        print("ğŸ’¥ èµ„äº§éªŒè¯å¤±è´¥ï¼")
        print("âŒ è¯·ä¿®å¤ä¸Šè¿°é—®é¢˜åé‡æ–°éªŒè¯")
        sys.exit(1)

if __name__ == '__main__':
    main()